import numpy as np
import pygame
import torch
import csv
import os
from pacman_env import PacmanEnv

# =================================================================
# [ì„¤ì •] ëª¨ë¸ íƒ€ì… ì„ íƒ
# ì˜µì…˜: "DQN", "DDQN", "DUELING"
MODEL_TYPE = "DDQN"
# =================================================================

# íŒŒì¼ëª… ìë™ ìƒì„±
log_filename = f"log_{MODEL_TYPE.lower()}.csv"
model_filename = f"pacman_{MODEL_TYPE.lower()}.pth"

# ëª¨ë¸ ì„ íƒ ë¡œì§
if MODEL_TYPE == "DQN":
    from dqn_agent import DQNAgent as Agent
elif MODEL_TYPE == "DDQN":
    from ddqn_agent import DDQNAgent as Agent
elif MODEL_TYPE == "DUELING":
    from dueling_agent import DuelingAgent as Agent
else:
    raise ValueError(f"Unknown Model Type: {MODEL_TYPE}")

def get_one_hot_state(grid):
    state_one_hot = np.zeros((5, 20, 20), dtype=np.float32)
    state_one_hot[0] = (grid == 0)
    state_one_hot[1] = (grid == 1)
    state_one_hot[2] = (grid == 2)
    state_one_hot[3] = (grid == 3)
    state_one_hot[4] = (grid == 4)
    return state_one_hot.flatten()

def main():
    # í•™ìŠµ ì†ë„ë¥¼ ë†’ì´ë ¤ë©´ renderë¥¼ ì•„ì˜ˆ ì•ˆ í•˜ëŠ” ê²Œ ì¢‹ìŠµë‹ˆë‹¤.
    # í™”ë©´ì„ ì•ˆ ë„ìš°ê³  ì‹¶ë‹¤ë©´ PacmanEnv() ë‚´ë¶€ì—ì„œ pygame.display.set_modeë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜
    # render() í•¨ìˆ˜ í˜¸ì¶œì„ ì•„ì˜ˆ ì§€ì›Œì•¼ í•˜ì§€ë§Œ, ì¼ë‹¨ ì—¬ê¸°ì„œëŠ” í˜¸ì¶œ ë¹ˆë„ë§Œ ì¤„ì…ë‹ˆë‹¤.
    env = PacmanEnv()
    state_size = 20 * 20 * 5
    action_size = 4

    agent = Agent(state_size, action_size)

    EPISODES = 5000

    print(f"--- Training Start: {MODEL_TYPE} ---")
    print(f"ğŸ“„ ë¡œê·¸ëŠ” '{log_filename}' íŒŒì¼ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
    print("ğŸš€ í•™ìŠµ ì¤‘... (í„°ë¯¸ë„ ì¶œë ¥ì€ 100 ì—í”¼ì†Œë“œë§ˆë‹¤ ê°±ì‹ ë©ë‹ˆë‹¤)")

    # CSV íŒŒì¼ ì´ˆê¸°í™”
    with open(log_filename, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Episode', 'Score', 'Steps', 'Epsilon', 'Avg_Loss', 'Wall_Hits', 'Coins'])

    for e in range(EPISODES):
        grid_state = env.reset()
        state = get_one_hot_state(grid_state)
        done = False
        total_reward = 0
        step_count = 0
        loss_list = []
        final_wall_hits = 0
        final_coins = 0

        while not done:
            for event in pygame.event.get():
                if event.type == pygame.QUIT:
                    env.close()
                    return

            action = agent.get_action(state)
            next_grid_state, reward, done, info = env.step(action)
            next_state = get_one_hot_state(next_grid_state)

            final_wall_hits = info['wall_hits']
            final_coins = info['coins_eaten']

            agent.remember(state, action, reward, next_state, done)
            loss = agent.train_step()
            if loss is not None:
                loss_list.append(loss)

            state = next_state
            total_reward += reward
            step_count += 1

            # [ì˜µì…˜] í•™ìŠµ í™”ë©´ë„ 100íŒì— í•œ ë²ˆë§Œ, í˜¹ì€ ì•„ì˜ˆ ì£¼ì„ ì²˜ë¦¬í•´ì„œ ë„ì„¸ìš”.
            if (e + 1) % 100 == 0:
                env.render()

        agent.update_target_network()
        agent.update_epsilon()

        avg_loss = np.mean(loss_list) if len(loss_list) > 0 else 0

        # 1. ë¡œê·¸ íŒŒì¼ ì €ì¥ì€ ë§¤ íŒ ìˆ˜í–‰ (ë°ì´í„° í™•ë³´ìš©)
        with open(log_filename, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([e+1, total_reward, step_count, agent.epsilon, avg_loss, final_wall_hits, final_coins])

        # 2. í„°ë¯¸ë„ ì¶œë ¥ì€ 100íŒë§ˆë‹¤ í•œ ë²ˆë§Œ (ìƒì¡´ ì‹ ê³ ìš©)
        if (e + 1) % 100 == 0:
            print(f"[{MODEL_TYPE}] Ep {e+1}/{EPISODES} | Score: {total_reward:.2f} | Wall: {final_wall_hits} | Coins: {final_coins} | Eps: {agent.epsilon:.2f}")

    env.close()
    torch.save(agent.model.state_dict(), model_filename)
    print(f"\nTraining Finished! Model saved as {model_filename}")

if __name__ == "__main__":
    main()