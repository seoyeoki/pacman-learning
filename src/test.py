import pygame
import torch
import time
import numpy as np
import csv
from datetime import datetime
from pacman_env import PacmanEnv

# =================================================================
# [ì„¤ì •] í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”.
# -----------------------------------------------------------------
# 1. "DQN"     : ê¸°ë³¸ DQN (Target Networkë§Œ ì‚¬ìš©)
# 2. "DDQN"    : Double DQN (ê³¼ëŒ€í‰ê°€ ë°©ì§€)
# 3. "DUELING" : Dueling DQN (ìƒíƒœ ê°€ì¹˜ì™€ í–‰ë™ ì´ì  ë¶„ë¦¬)
# 4. "RANDOM"  : í•™ìŠµ ì—†ëŠ” ë¬´ì‘ìœ„ í–‰ë™ (ë¹„êµìš©)
# -----------------------------------------------------------------
MODEL_TYPE = "DDQN"
# =================================================================

# 1. í˜„ì¬ ì‹œê°„ êµ¬í•˜ê¸° (íŒŒì¼ëª…ìš©)
current_time = datetime.now().strftime("%Y%m%d_%H%M%S")

# 2. ê²°ê³¼ íŒŒì¼ëª… ìƒì„± (ë§¤ë²ˆ ìƒˆë¡œìš´ íŒŒì¼)
RESULT_FILENAME = f"test_result_{MODEL_TYPE}_{current_time}.csv"


# --- ëª¨ë¸ íƒ€ì…ì— ë”°ë¥¸ í´ë˜ìŠ¤ ë° íŒŒì¼ ì„¤ì • ---
if MODEL_TYPE == "RANDOM":
    from src.model_agent.random_agent import RandomAgent as AgentClass
    model_filename = None

elif MODEL_TYPE == "DQN":
    from src.model_agent.dqn_agent import DQNAgent as AgentClass
    model_filename = "../trained_pth/pacman_dqn.pth"

elif MODEL_TYPE == "DDQN":
    from src.model_agent.ddqn_agent import DDQNAgent as AgentClass
    model_filename = "../trained_pth/pacman_ddqn.pth"

elif MODEL_TYPE == "DUELING":
    from dueling_agent import DuelingAgent as AgentClass
    model_filename = "pacman_dueling.pth"

else:
    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…ì…ë‹ˆë‹¤: {MODEL_TYPE}")


def get_one_hot_state(grid):
    state_one_hot = np.zeros((5, 20, 20), dtype=np.float32)
    state_one_hot[0] = (grid == 0)
    state_one_hot[1] = (grid == 1)
    state_one_hot[2] = (grid == 2)
    state_one_hot[3] = (grid == 3)
    state_one_hot[4] = (grid == 4)
    return state_one_hot.flatten()

def save_result_to_csv(model_type, score, steps, wall_hits, coins):
    """ê²°ê³¼ ì €ì¥ í•¨ìˆ˜"""
    with open(RESULT_FILENAME, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Timestamp', 'Model_Type', 'Score', 'Steps', 'Wall_Hits', 'Coins'])

        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        writer.writerow([timestamp, model_type, score, steps, wall_hits, coins])

    print(f"ğŸ’¾ ì„±ì í‘œ ì €ì¥ ì™„ë£Œ: {RESULT_FILENAME}")

def run_test():
    env = PacmanEnv()
    state_size = 20 * 20 * 5
    action_size = 4

    # ì—ì´ì „íŠ¸ ê°ì²´ ìƒì„±
    # RANDOM ëª¨ë¸ì€ state_sizeê°€ í•„ìš” ì—†ì§€ë§Œ, ì½”ë“œ í†µì¼ì„±ì„ ìœ„í•´ ì¸ì ì²˜ë¦¬ëŠ” í´ë˜ìŠ¤ ë‚´ë¶€ì—ì„œ í•˜ê±°ë‚˜ ì—¬ê¸°ì„œ ë¶„ê¸°
    if MODEL_TYPE == "RANDOM":
        agent = AgentClass(action_size)
    else:
        agent = AgentClass(state_size, action_size)

    print(f"\n=== ğŸ® {MODEL_TYPE} ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {RESULT_FILENAME}")

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (RANDOMì´ ì•„ë‹ ë•Œë§Œ)
    if MODEL_TYPE != "RANDOM":
        print(f"ğŸ“‚ ëª¨ë¸ íŒŒì¼ ë¡œë”© ì¤‘: {model_filename}")
        try:
            # map_location='cpu'ëŠ” GPUê°€ ì—†ëŠ” í™˜ê²½ì—ì„œë„ ë¡œë“œë˜ê²Œ í•´ì¤ë‹ˆë‹¤.
            agent.model.load_state_dict(torch.load(model_filename, map_location=torch.device('cpu')))
            agent.epsilon = 0.0  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ (íƒí—˜ X)
            print(f">>> ë¡œë“œ ì„±ê³µ! AIê°€ í”Œë ˆì´í•©ë‹ˆë‹¤.")
        except FileNotFoundError:
            print(f">>> ğŸš¨ ì˜¤ë¥˜: '{model_filename}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print(f">>> ë¨¼ì € train.pyì—ì„œ í•´ë‹¹ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ì£¼ì„¸ìš”.")
            return
    else:
        print(">>> ğŸ² ë¬´ì‘ìœ„(Random) í”Œë ˆì´ì–´ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    grid_state = env.reset()
    state = get_one_hot_state(grid_state)
    done = False
    total_reward = 0
    step = 0
    final_wall_hits = 0
    final_coins = 0

    print("--- Game Start ---")

    while not done:
        for event in pygame.event.get():
            if event.type == pygame.QUIT:
                env.close()
                return

        action = agent.get_action(state)
        next_grid_state, reward, done, info = env.step(action)
        state = get_one_hot_state(next_grid_state)

        final_wall_hits = info['wall_hits']
        final_coins = info['coins_eaten']
        total_reward += reward
        step += 1

        env.render()
        time.sleep(0.03) # ê´€ì „ ì†ë„

    print("-" * 40)
    print(f"[{MODEL_TYPE}] í…ŒìŠ¤íŠ¸ ì¢…ë£Œ")
    print(f"ğŸ† ìµœì¢… ì ìˆ˜ : {total_reward:.2f}")
    print(f"ğŸ¦¶ ìƒì¡´ ìŠ¤í… : {step}")
    print(f"ğŸ’¥ ë²½ ì¶©ëŒìˆ˜ : {final_wall_hits}")
    print(f"ğŸª™ ì½”ì¸ íšë“ : {final_coins}")
    print("-" * 40)

    save_result_to_csv(MODEL_TYPE, total_reward, step, final_wall_hits, final_coins)
    time.sleep(2)
    env.close()

if __name__ == "__main__":
    run_test()